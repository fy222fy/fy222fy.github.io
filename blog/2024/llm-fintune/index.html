<!DOCTYPE html> <html lang="zh-cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 大模型微调技术梳理 | Haonan Feng </title> <meta name="author" content="Haonan Feng"> <meta name="description" content="this is what included tabs in a post could look like"> <meta name="keywords" content="AI Security &amp; Formal Verification"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?2b8ae22354b0523281291bc7c947047f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fy222fy.github.io/blog/2024/llm-fintune/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Haonan</span> Feng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">关于 </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">发表作品 </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">简历 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">博客 </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">仓库 </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">动态 </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item active"> <a class="nav-link" href="/en-us/blog/2024/llm-fintune/"> EN-US</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">大模型微调技术梳理</h1> <p class="post-meta"> 创建时间 01 de 五月, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> ai</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="背景知识">背景知识</h1> <p><strong>FineTune（微调）</strong> 大模型微调技术是指在<strong>已经预训练好</strong>的大型语言模型基础上，使用特定的数据集进行<strong>进一步</strong>的训练，以使模型适应<strong>特定任务</strong>或领域。这种方式有如下的优势：</p> <ol> <li>微调后的模型仍具备原有大模型的特征；</li> <li>仅需要少量数据集就可以达到不错的效果，免去了重新训练模型；</li> <li>训练成本低。</li> </ol> <p>大模型微调技术主要分为如下两类：</p> <ol> <li>全量微调（Full Fine-Tuning，FFT）：即<strong>全部参数</strong>都微调，但对于大模型来说，参数量巨大导致全量微调需要消耗大量算力，实用性不高，此外，全量微调会造成灾难性遗忘，会在把某领域方面表现变好的同时，把原来表现好的其他领域的能力变差；</li> <li>高效微调（Parameter-Efficient Fine-Tuning，PEFT）：针对<strong>部分参数</strong>进行训练和调整，解决了全量微调的缺陷，使大模型在某个领域的能力提升。</li> </ol> <p>本篇主要介绍高效微调，包括如下几种：</p> <ol> <li><strong>Freeze Tuning</strong></li> <li><strong>Adapter Tuning</strong></li> <li><strong>Prompt Tuning</strong></li> <li><strong>P-Tuning</strong></li> <li><strong>Prefix-Tuning</strong></li> <li><strong>P-Tuning V2</strong></li> <li><strong>LoRa Tuning</strong></li> </ol> <h1 id="freeze-tuning">Freeze Tuning</h1> <p>Freeze参数冻结，对大模型的大部分参数进行冻结，仅训练少部分参数，以此来减少显存占用，完成微调。</p> <h1 id="adapter-tuning">Adapter Tuning</h1> <p><a href="https://arxiv.org/pdf/1902.00751.pdf" rel="external nofollow noopener" target="_blank">《Parameter-Efficient Transfer Learning for NLP》</a> 2019 论文指出，Freeze Tuning难以达到较好的效果。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/1-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/1-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Adapter Tuning主要是在Transformer模块中增加了一个适配层。</p> <p>子层1：将Transformer块的输出作为输入，将原始维度d投影到m维度，m的大小决定了Adapter模块的参数量，m«d。</p> <p>子层2：在输出时，通过第二个子层还原输入维度，将m投影到d。</p> <p>优点：</p> <p>主要解决了灾难性遗忘，任务之间的干扰和训练不稳定的问题。</p> <h1 id="prompt-tuning">Prompt Tuning</h1> <p>Prompt：提示词，用于引导模型生成文本的一段输入，帮助模型更好理解用户意图，这种输入可以是明确的单词（Hard Prompt，离散Prompt），也可以是一个一个向量（Soft Prompt，连续Prompt）。</p> <ul> <li>Prompt Engineering：通过人工开发和优化Prompt，帮助语言模型用于各个应用场景和领域。</li> <li>Prompt Tuning：通过AI优化Prompt，达到最好的Prompt效果，适配各个场景。</li> </ul> <h2 id="背景">背景</h2> <p>大模型本身具备很强的推理和理解能力， GPT3在<a href="https://arxiv.org/abs/2005.14165" rel="external nofollow noopener" target="_blank">《Language Models are Few-Shot Learners》</a>提出in-context learning概念， 无需修改模型，通过few-shot/zero-shot/demonstrate-learning，让模型知道和标签相似的语义，提升推理能力。 在真实场景中，例如在GPT3不那么大的模型中，Prommpt直接用在zero-shot上效果下降，且对于一些具体的任务场景，需要单独设计组件实现。 于是出现了PET（Pattern-Exploiting Training）模型 <a href="https://arxiv.org/pdf/2001.07676.pdf%C3%AF%C2%BC%E2%80%B0" rel="external nofollow noopener" target="_blank">《Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference》</a>。</p> <p>以NLI（预测两句话之间的关系）为例：</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/2-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/2-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="基本原理">基本原理</h2> <p>Prompt-Tuning的主要组件称为Pattern-Verbalizer-Pair。</p> <ul> <li>Pattern：带[mask]标记的短文本，是希望模型预测的标记，可以是任何词。</li> <li>PLM：预训练的模型。</li> <li>Verbalizer：标签词映射，对于具体分类任务，选择指定的标签词。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/3-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/3-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>为达到更好的效果，可以有多种方法：</p> <ul> <li>Patterns Ensembling：为一个句子设计不同的Pattern；</li> <li>Verbalizers Ensembling：标签词可以有多个，例如great、nice都可以是积极的；</li> <li>PVPs Ensembling：多个PVP组件，采用加权、投票等形式获得结果。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/4-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/4-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>基于PVP框架，Prompt Tuning的重点就在于如何选择和构造合适的Pattern和Verbalizer。</p> <h3 id="微调模板">微调模板</h3> <p>最简单的方式就是人工设计模板，但自动化的方式更好。 离散模板构建法（Hard Template 、 Hard Prompt 、 Discrete Template 、 Discrete Prompt），在训练过程中保持不变，且是离散的词向量。包括：</p> <ul> <li>人工构建（Manual Template） ：在前文已经描述过，不再详细说明；</li> <li>启发式法（Heuristic-based Template） ：通过规则、启发式搜索等方法构建合适的模板；</li> <li>生成（Generation） ：根据给定的任务训练数据（通常是小样本场景），生成出合适的模板；</li> </ul> <p>连续模板构建（Soft Template 、 Soft Prompt 、 Continuous Template 、 Continuous Prompt），在连续的向量空间寻找合适的标记，解决离散模版容易陷入局部最优的问题。</p> <ul> <li>词向量微调（Word Embedding） ：显式地定义离散字符的模板，但在训练时这些模板字符的词向量参与梯度下降，初始定义的离散字符用于作为向量的初始化；</li> <li>伪标记（Pseudo Token） ：不显式地定义离散的模板，而是将模板作为可训练的参数；</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/5-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/5-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4 id="启发式构建模板">启发式构建模板</h4> <p>采用规则、正则化的模板构建出Pattern，或用启发式的搜索算法获得Pattern。 例如，可以利用启发式的规则定义若干个子模板，自动组合形成最终Pattern。 例如，<a href="https://arxiv.org/pdf/2010.15980.pdf" rel="external nofollow noopener" target="_blank">AutoPrompt</a>给定原始的输入，额外定义若干离散的字符作为trigger， 并组成Template，喂入MLM中预测对应label word的概率。而这些trigger最终通过梯度搜索的方法进行挑选。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/6-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/6-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/6-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4 id="生成法构建">生成法构建</h4> <p>直接让模型来生成合适的模板。 首先定义一个Template的母版，将这些母版与原始文本拼接后喂入T5模型（T5模型属于自回归式的生成模型）后在<x>和<y>占位符部分生成相应的字符， 最终形成对应的Template。然后再基于生成的Template和label word进行训练。</y></x></p> <p><img src="https://i-blog.csdnimg.cn/blog_migrate/de969f0730c54b7e302caf54078b035d.png" alt="image.png"></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/7-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/7-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/7-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4 id="连续提示模板">连续提示模板</h4> <p>不论是启发式方法，还是通过生成的方法，都需要为每一个任务单独设计对应的模板，因为这些模板都是可读的离散的token（这类模板我们称作Discrete Prompt或Hard Prompt）， 这导致很难寻找到最佳的模板。 另外，即便是同一个任务，不同的句子也会有其所谓最佳的模板，而且有时候，即便是人类理解的相似的模板，也会对模型预测结果产生很大差异。 为避免这种问题，将模板转换为可进行优化的连续向量，不同的任务、数据可以自适应地在语义空间中寻找若干合适的向量，来代表模板中的每一个词， 相较于显式的token，这类token称为 <strong>伪标记（Pseudo Token）</strong>。</p> <p>代表的几种方法有：</p> <ul> <li> <a href="https://arxiv.org/pdf/2104.08691.pdf?trk=public_post_comment-text" rel="external nofollow noopener" target="_blank">《The Power of Scale for Parameter-Efficient Prompt Tuning》</a>2021：代表方法为Prompt Tuning</li> <li> <a href="https://arxiv.org/abs/2103.10385" rel="external nofollow noopener" target="_blank">《GPT Understands, Too》</a>2021：P-tuning</li> <li> <a href="https://arxiv.org/pdf/2110.07602.pdf" rel="external nofollow noopener" target="_blank">《P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks》</a>2021</li> <li> <a href="https://arxiv.org/pdf/2109.04332.pdf" rel="external nofollow noopener" target="_blank">《PPT: Pre-trained Prompt Tuning for Few-shot Learning》</a>2021：代表方法PPT</li> <li> <a href="https://arxiv.org/pdf/2101.00190.pdf%EF%BC%89" rel="external nofollow noopener" target="_blank">《Prefix-Tuning: Optimizing Continuous Prompts for Generation》</a>2021</li> </ul> <h3 id="微调verbalizer">微调Verbalizer</h3> <p>Verbalizer也会影响预测的结果，和模板类似，Verbalizer也分为离散和连续两种类型。</p> <ul> <li>人工设计：根据对每个任务的经验来人工指定这些label word。但是人工设计需要依赖大量的人力；</li> <li>领域知识指导搜索离散的label word，代表方法为KPT，<a href="https://arxiv.org/pdf/2108.02035.pdf" rel="external nofollow noopener" target="_blank">《Knowledgeable Prompt-tuning:Incorporating Knowledge into Prompt Verbalizer for Text Classification》</a>；</li> <li>原型网络动态生成label representations：<a href="https://arxiv.org/pdf/2203.09770.pdf" rel="external nofollow noopener" target="_blank">《Prototypical Verbalizer for Prompt-based Few-shot Tuning》</a>，代表方法为ProtoVerb</li> </ul> <h2 id="prompt-tuning-1">Prompt Tuning</h2> <p>这里说的是<a href="https://arxiv.org/pdf/2104.08691.pdf?trk=public_post_comment-text" rel="external nofollow noopener" target="_blank">《The Power of Scale for Parameter-Efficient Prompt Tuning》</a> 里的Prompt Tuning。其实是Prefix Tuning的一个简化版本。 基本概念：给每个任务定义prompt tokens，只在输入层加入这些tokens（训练的就是这些tokens）。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/8-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/8-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/8-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Prompts提出了Prompt Ensembling，在一个批次里面可以同时训练一个任务的不同prompt（采用多种不同方式询问同一个问题），提升了效率。</p> <h2 id="p-tuning">P-Tuning</h2> <p><a href="https://arxiv.org/abs/2103.10385" rel="external nofollow noopener" target="_blank">《GPT Understands, Too》</a> P-Tuning用MLP + LSTM（长短期记忆网络）的方式对Prompt Embedding进行一层处理，其虚拟token可以插入到除了前缀的任意位置。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/9-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/9-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/9-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>在训练过程中，PML模型的参数全部固定，微调的事Prompt Encoder，也就是LSTM的参数，这个参数是所有任务共享的。 预测过程中不需要这个组件，针对特定任务，LSTM输出独一无二的虚拟token embedding，插入到输入token中即可。</p> <h2 id="prefix-tuning">Prefix Tuning</h2> <p><a href="https://arxiv.org/pdf/2101.00190.pdf%EF%BC%89" rel="external nofollow noopener" target="_blank">《Prefix-Tuning: Optimizing Continuous Prompts for Generation》</a> 基本概念：固定训练的LM，添加任务特定的，可训练的前缀（训练的是这个embedding的前缀）。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/10-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/10-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/10-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>具体原理： 在输入token之前构造一段任务相关的virtual tokens作为Prefix，然后训练的时候只更新Prefix部分的参数，而PLM中的其他部分参数固定。 针对不同的模型结构，需要构造不同的Prefix。</p> <ul> <li>针对自回归架构模型：在句子前面添加前缀，得到 z = [PREFIX; x; y]，合适的上文能够在固定 LM 的情况下去引导生成下文（比如：GPT3的上下文学习）。</li> <li>针对编码器-解码器架构模型：Encoder和Decoder都增加了前缀，得到 z = [PREFIX; x; PREFIX0; y]。</li> <li>Encoder端增加前缀是为了引导输入部分的编码，Decoder 端增加前缀是为了引导后续token的生成。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/11-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/11-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/11-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>为了达到更好的效果：</p> <ol> <li>Deep Continuous Prompt：一般做法是在embedding层加入可训练的virtual token，但实际上可以在每一层都加入可训练的prefix。</li> <li>套MLP：因为直接优化可能导致不稳定和性能下降，所以在训练的过程中增加MLP映射矩阵。</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/12-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/12-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/12-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="p-tuning-v2">P-Tuning V2</h2> <p><a href="https://arxiv.org/pdf/2110.07602.pdf" rel="external nofollow noopener" target="_blank">《P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks》</a>2021 背景：</p> <p>从原理上，P-Tuning V2和Prefix Tuning是一样的，只不过Prefix Tuning针对NLG（自然语言生成）任务， 而P-Tuning v2进行了改进，可以用于NLU（自然语言理解）任务，如语义识别，情感分析等。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts/2024-04-05-llm-fintune-img/13-480.webp 480w,/assets/posts/2024-04-05-llm-fintune-img/13-800.webp 800w,/assets/posts/2024-04-05-llm-fintune-img/13-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts/2024-04-05-llm-fintune-img/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h1 id="lora-tuning">LoRA Tuning</h1> <p><a href="https://arxiv.org/pdf/2106.09685.pdf" rel="external nofollow noopener" target="_blank">《LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS》</a></p> <p>LoRa（Low-Rank Adaptation）基于一个假设：现有大模型的参数量是过度的，其背后有一批生成关键结果的参数，被称作低维本质模型。</p> <h2 id="原理">原理</h2> <p>全量微调：</p> <p>图左是全量微调的模型，表示预训练模型的权重矩阵，在反向传播的过程中，更新一个，更新后的权重矩阵为，如果模型有6B个参数，则也有6B个参数，非常消耗资源。</p> <p>Lora微调：</p> <p>图右是Lora微调，Lora将分解为两个低秩的矩阵，的行数和相同，的列数和相同，另外一个维度的长度是一个超参数，那么。微调时只需要训练A和B即可，因为的值很小（如4，8，16），所以资源消耗很少。</p> <p>原理：</p> <p>在Lora微调过程中，权重固定不变，控制矩阵为随机初始化矩阵，矩阵为0矩阵。 在前向过程中，初始权重和旁路矩阵都会作用于输入： 反向传播过程中，更新矩阵。 预测时同理。</p> <h2 id="优点">优点</h2> <ol> <li>节省资源：秩 r 是一个超参数。例如，如果 ΔW 有 10,000 行和 20,000 列，则需存储 200,000,000 个参数。如果我们选择 r=8 的 A 和 B，则 A 有 10,000 行和 8 列，B 有 8 行和 20,000 列，即 10,000×8 + 8×20,000 = 240,000 个参数，比 200,000,000 个参数少约 830 倍。</li> <li>预测性能损耗低</li> <li>便于切换场景：每个场景对应于一个矩阵，切换场景进需要做矩阵加减法即可：</li> <li>效果好</li> </ol> <h2 id="开源实现">开源实现</h2> <p>目前 LORA 已经被 HuggingFace 集成在了 <a href="https://link.zhihu.com/?target=https%3A//github.com/huggingface/peft" rel="external nofollow noopener" target="_blank">PEFT（Parameter-Efficient Fine-Tuning）</a> 代码库里。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">喜欢这篇文章？</h2> <p class="mb-2">这里是一些其他的文章：</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/deploy-my-server/">配置新的linux服务器并安装iterm2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/k8s-pouch/">kubernetes（K8s）+ pouch三主高可用集群部署</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/c-left-right/">C++中左值和右值是什么以及存在的理解误区</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/sort-c/">C++实现不同的排序算法，以及实现过程中的难点</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/c-multiple/">C++中&amp;和*的含义</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Haonan Feng. Desenvolvido em <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> com o tema <a href="https://github.com/george-gca/multi-language-al-folio" rel="external nofollow noopener" target="_blank">multi-language-al-folio</a>. Hospedado por <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Fotos do <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="点击搜索"> <div class="modal-footer" slot="footer"> <span class="help"> <svg version="1.0" class="ninja-examplekey" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 1280 1280"> <path d="M1013 376c0 73.4-.4 113.3-1.1 120.2a159.9 159.9 0 0 1-90.2 127.3c-20 9.6-36.7 14-59.2 15.5-7.1.5-121.9.9-255 1h-242l95.5-95.5 95.5-95.5-38.3-38.2-38.2-38.3-160 160c-88 88-160 160.4-160 161 0 .6 72 73 160 161l160 160 38.2-38.3 38.3-38.2-95.5-95.5-95.5-95.5h251.1c252.9 0 259.8-.1 281.4-3.6 72.1-11.8 136.9-54.1 178.5-116.4 8.6-12.9 22.6-40.5 28-55.4 4.4-12 10.7-36.1 13.1-50.6 1.6-9.6 1.8-21 2.1-132.8l.4-122.2H1013v110z"></path> </svg> to select </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M20 12l-1.41-1.41L13 16.17V4h-2v12.17l-5.58-5.59L4 12l8 8 8-8z"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path> </svg> to navigate </span> <span class="help"> <span class="ninja-examplekey esc">esc</span> to close </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey backspace" viewbox="0 0 20 20" fill="currentColor"> <path fill-rule="evenodd" d="M6.707 4.879A3 3 0 018.828 4H15a3 3 0 013 3v6a3 3 0 01-3 3H8.828a3 3 0 01-2.12-.879l-4.415-4.414a1 1 0 010-1.414l4.414-4.414zm4 2.414a1 1 0 00-1.414 1.414L10.586 10l-1.293 1.293a1 1 0 101.414 1.414L12 11.414l1.293 1.293a1 1 0 001.414-1.414L13.414 10l1.293-1.293a1 1 0 00-1.414-1.414L12 8.586l-1.293-1.293z" clip-rule="evenodd"></path> </svg> move to parent </span> </div> </ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-\u5173\u4e8e",title:"\u5173\u4e8e",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/"}},{id:"nav-\u53d1\u8868\u4f5c\u54c1",title:"\u53d1\u8868\u4f5c\u54c1",description:"\u8bba\u6587\u3001\u671f\u520a\u3001\u4e13\u5229",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/publications/"}},{id:"nav-\u7b80\u5386",title:"\u7b80\u5386",description:"\u5317\u4eac\u90ae\u7535\u5927\u5b66\uff0c\u7f51\u7edc\u7a7a\u95f4\u5b89\u5168\u5b66\u9662\u535a\u58eb\u751f",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/cv/"}},{id:"nav-\u535a\u5ba2",title:"\u535a\u5ba2",description:"\u5b66\u4e60\u662f\u4e00\u79cd\u79ef\u7d2f\uff0c\u4e00\u70b9\u70b9\u79f0\u4e3a\u66f4\u597d\u7684\u81ea\u5df1\u3002",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/blog/"}},{id:"nav-\u4ed3\u5e93",title:"\u4ed3\u5e93",description:"\u76f8\u5173\u5f00\u6e90\u9879\u76ee",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/repositories/"}},{id:"nav-\u52a8\u6001",title:"\u52a8\u6001",description:"",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/news/"}},{id:"post-\u914d\u7f6e\u65b0\u7684linux\u670d\u52a1\u5668\u5e76\u5b89\u88c5iterm2",title:"\u914d\u7f6e\u65b0\u7684linux\u670d\u52a1\u5668\u5e76\u5b89\u88c5iterm2",description:"\u670d\u52a1\u5668\u90e8\u7f72",section:"Posts",handler:()=>{window.location.href="/blog/2024/deploy-my-server/"}},{id:"post-\u5927\u6a21\u578b\u5fae\u8c03\u6280\u672f\u68b3\u7406",title:"\u5927\u6a21\u578b\u5fae\u8c03\u6280\u672f\u68b3\u7406",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/llm-fintune/"}},{id:"post-kubernetes-k8s-pouch\u4e09\u4e3b\u9ad8\u53ef\u7528\u96c6\u7fa4\u90e8\u7f72",title:"kubernetes\uff08K8s\uff09+ pouch\u4e09\u4e3b\u9ad8\u53ef\u7528\u96c6\u7fa4\u90e8\u7f72",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/k8s-pouch/"}},{id:"post-c-\u4e2d\u5de6\u503c\u548c\u53f3\u503c\u662f\u4ec0\u4e48\u4ee5\u53ca\u5b58\u5728\u7684\u7406\u89e3\u8bef\u533a",title:"C++\u4e2d\u5de6\u503c\u548c\u53f3\u503c\u662f\u4ec0\u4e48\u4ee5\u53ca\u5b58\u5728\u7684\u7406\u89e3\u8bef\u533a",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/c-left-right/"}},{id:"post-c-\u5b9e\u73b0\u4e0d\u540c\u7684\u6392\u5e8f\u7b97\u6cd5-\u4ee5\u53ca\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u7684\u96be\u70b9",title:"C++\u5b9e\u73b0\u4e0d\u540c\u7684\u6392\u5e8f\u7b97\u6cd5\uff0c\u4ee5\u53ca\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u7684\u96be\u70b9",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/sort-c/"}},{id:"post-c-\u4e2d-amp-\u548c-\u7684\u542b\u4e49",title:"C++\u4e2d&\u548c*\u7684\u542b\u4e49",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/c-multiple/"}},{id:"post-\u901a\u8fc7\u6700\u5927\u5b50\u5e8f\u548c\u7b97\u6cd5\u9898\u5b66\u4e60\u5206\u6cbb\u6cd5-\u51cf\u6cbb\u6cd5-\u52a8\u6001\u89c4\u5212-\u8d2a\u5fc3\u7b97\u6cd5",title:"\u901a\u8fc7\u6700\u5927\u5b50\u5e8f\u548c\u7b97\u6cd5\u9898\u5b66\u4e60\u5206\u6cbb\u6cd5\u3001\u51cf\u6cbb\u6cd5\u3001\u52a8\u6001\u89c4\u5212\u3001\u8d2a\u5fc3\u7b97\u6cd5",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/Dynamic-Programming/"}},{id:"post-windows\u7cfb\u7edf\u5982\u4f55\u5b89\u88c5proverif-editor",title:"Windows\u7cfb\u7edf\u5982\u4f55\u5b89\u88c5ProVerif Editor",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/ProVerif-editor/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"news-\u8bba\u6587-a-formal-analysis-of-the-fido-uaf-protocol-\u88abndss\u5f55\u7528\u4e86-sparkles-smile",title:'\u8bba\u6587\u300aA Formal Analysis of the FIDO UAF Protocol\u300b\u88abNDSS\u5f55\u7528\u4e86\uff01 <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"\u6700\u65b0\u52a8\u6001"},{id:"news-\u8bba\u6587-fido-gets-verified-a-formal-analysis-of-the-universal-authentication-framework-protocol-\u88abtdsc\u5f55\u7528\u4e86-sparkles-smile",title:'\u8bba\u6587\u300aFIDO gets verified: A formal analysis of the universal authentication framework protocol\u300b\u88abTDSC\u5f55\u7528\u4e86\uff01 <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">...',description:"",section:"\u6700\u65b0\u52a8\u6001"},{id:"news-\u8682\u8681\u96c6\u56e2\u53d1\u5e03-\u53ef\u4fe1\u5bc6\u6001\u8ba1\u7b97\u767d\u76ae\u4e66-https-gw-alipayobjects-com-os-bmw-prod-56176409-5afa-4e86-85f7-1060116c01af-pdf",title:"\u8682\u8681\u96c6\u56e2\u53d1\u5e03[\u300a\u53ef\u4fe1\u5bc6\u6001\u8ba1\u7b97\u767d\u76ae\u4e66\u300b](https://gw.alipayobjects.com/os/bmw-prod/56176409-5afa-4e86-85f7-1060116c01af.pdf)",description:"",section:"\u6700\u65b0\u52a8\u6001"},{id:"news-\u8682\u8681\u96c6\u56e2\u53d1\u5e03-\u5927\u6a21\u578b\u5bc6\u7b97\u5e73\u53f0-https-databridge-misuan-cloud-alipay-com-portal-\u8ba9\u6570\u636e\u50cf\u81ea\u6765\u6c34\u4e00\u6837\u53ef\u4fe1\u6d41\u901a",title:"\u8682\u8681\u96c6\u56e2\u53d1\u5e03[\u5927\u6a21\u578b\u5bc6\u7b97\u5e73\u53f0](https://databridge-misuan.cloud.alipay.com/portal)\uff0c \u8ba9\u6570\u636e\u50cf\u81ea\u6765\u6c34\u4e00\u6837\u53ef\u4fe1\u6d41\u901a\u3002",description:"",section:"\u6700\u65b0\u52a8\u6001"},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"projects-projeto-1",title:"projeto 1",description:"com imagem de fundo",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-projeto-2",title:"projeto 2",description:"um projeto com imagem de fundo e coment\xe1rios do giscus",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-projeto-3-com-um-nome-bem-longo",title:"projeto 3 com um nome bem longo",description:"um projeto que redireciona pra outro website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-projeto-4",title:"projeto 4",description:"outro sem imagem",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-projeto-5",title:"projeto 5",description:"um projeto com imagem de fundo",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-projeto-6",title:"projeto 6",description:"um projeto sem imagem",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"socials-email",title:"\u53d1\u9001\u90ae\u4ef6",section:"\u793e\u4ea4\u5a92\u4f53",handler:()=>{window.open("mailto:%66%65%6E%67%68%61%6F%6E%61%6E%32%32%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"\u793e\u4ea4\u5a92\u4f53",handler:()=>{window.open("https://scholar.google.com/citations?user=ruPrB9wAAAAJ","_blank")}},{id:"lang-en-us",title:"en-us",section:"\u8bed\u8a00",handler:()=>{window.location.href="/en-us/blog/2024/llm-fintune/"}},{id:"light-theme",title:"\u5207\u6362\u767d\u5929\u4e3b\u9898",description:"\u5207\u6362\u7f51\u9875\u4e3b\u9898\u81f3\u767d\u5929",section:"\u4e3b\u9898",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"\u5207\u6362\u4e3b\u9898\u5230\u9ed1\u591c\u6a21\u5f0f",description:"\u5207\u6362\u7f51\u9875\u4e3b\u9898\u5230\u9ed1\u591c\u6a21\u5f0f",section:"\u4e3b\u9898",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"\u4f7f\u7528\u7cfb\u7edf\u9ed8\u8ba4\u4e3b\u9898",description:"\u5207\u6362\u4e3b\u9898\u81f3\u7cfb\u7edf\u9ed8\u8ba4",section:"\u4e3b\u9898",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>